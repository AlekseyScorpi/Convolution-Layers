{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "236b32db",
   "metadata": {},
   "source": [
    "### Транспонированная 2D свертка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88310f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class ConvTranspose2D():\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, dtype=None):\n",
    "        \n",
    "        self.weights = None\n",
    "        self.bias_weights = None\n",
    "        \n",
    "        self.dtype = dtype\n",
    "        \n",
    "        if isinstance(in_channels, int) and in_channels > 0:\n",
    "            self.in_channels = in_channels\n",
    "        else:\n",
    "            raise ValueError(\"Invalid in_channels\")\n",
    "        \n",
    "        if isinstance(out_channels, int) and out_channels > 0:\n",
    "            self.out_channels = out_channels\n",
    "        else:\n",
    "            raise ValueError(\"Invalid out_channels\")\n",
    "        \n",
    "        if isinstance(groups, int) and groups > 0:\n",
    "            self.groups = groups\n",
    "        else:\n",
    "            raise ValueError(\"Invalid groups\")\n",
    "        \n",
    "        if isinstance(bias, int) or isinstance(bias, bool):\n",
    "            self.bias = bool(bias)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid bias\")\n",
    "        \n",
    "        if isinstance(kernel_size, tuple):\n",
    "            try:\n",
    "                self.kernel1, self.kernel2 = kernel_size\n",
    "                if not (isinstance(self.kernel1, int) and isinstance(self.kernel2, int)):\n",
    "                    raise ValueError(\"Invalid kernel_size types\")\n",
    "            except ValueError:\n",
    "                raise ValueError(\"Invalid tuple format for kernel_size\")\n",
    "        elif isinstance(kernel_size, int) and kernel_size > 0:\n",
    "            self.kernel1 = self.kernel2 = kernel_size\n",
    "        else:\n",
    "            raise ValueError(\"Invalid kernel_size\")\n",
    "        \n",
    "        if isinstance(stride, tuple):\n",
    "            try:\n",
    "                self.stride1, self.stride2 = stride\n",
    "                if not (isinstance(self.stride1, int) and isinstance(self.stride2, int)):\n",
    "                    raise ValueError(\"Invalid stride types\")\n",
    "            except ValueError:\n",
    "                raise ValueError(\"Invalid tuple format for stride\")\n",
    "        elif isinstance(stride, int) and stride > 0:\n",
    "            self.stride1 = self.stride2 = stride\n",
    "        else:\n",
    "            raise ValueError(\"Invalid stride\")\n",
    "        \n",
    "        if isinstance(padding, tuple):\n",
    "            try:\n",
    "                self.padding1, self.padding2 = padding\n",
    "                if not (isinstance(self.padding1, int) and isinstance(self.padding2, int)):\n",
    "                    raise ValueError(\"Invalid padding types\")\n",
    "            except ValueError:\n",
    "                raise ValueError(\"Invalid tuple format for padding\")\n",
    "        elif isinstance(padding, int) and padding > -1:\n",
    "            self.padding1 = self.padding2 = padding\n",
    "        else:\n",
    "            raise ValueError(\"Invalid padding\")\n",
    "            \n",
    "        if isinstance(output_padding, tuple):\n",
    "            try:\n",
    "                self.output_padding1, self.output_padding2 = padding\n",
    "                if not (isinstance(self.output_padding1, int) and isinstance(self.output_padding2, int)):\n",
    "                    raise ValueError(\"Invalid output_padding types\")\n",
    "            except ValueError:\n",
    "                raise ValueError(\"Invalid tuple format for output_padding\")\n",
    "        elif isinstance(output_padding, int) and output_padding > -1:\n",
    "            self.output_padding1 = self.output_padding2 = output_padding\n",
    "        else:\n",
    "            raise ValueError(\"Invalid output_padding\")\n",
    "            \n",
    "        if isinstance(dilation, tuple):\n",
    "            try:\n",
    "                self.dilation1, self.dilation2 = dilation\n",
    "                if not (isinstance(self.dilation1, int) and isinstance(self.dilation2, int)):\n",
    "                    raise ValueError(\"Invalid dilation types\")\n",
    "            except ValueError:\n",
    "                raise ValueError(\"Invalid tuple format for dilation\")\n",
    "        elif isinstance(dilation, int) and dilation > 0:\n",
    "            self.dilation1 = self.dilation2 = dilation\n",
    "        else:\n",
    "            raise ValueError(\"Invalid dilation\")\n",
    "        if not((self.in_channels % self.groups == 0) and (self.out_channels % self.groups == 0)):\n",
    "            raise ValueError(\"in_channels and out_channels must both be divisible by groups\")\n",
    "        \n",
    "        if (self.output_padding1 >= self.dilation1 and self.output_padding1 >= self.stride1) or (self.output_padding2 >= self.dilation2 and self.output_padding2 >= self.stride2):\n",
    "            raise ValueError(\"output_padding should be smaller than dilation or stride\")\n",
    "            \n",
    "    def set_weights(self, weights, bias = None):\n",
    "        if self.bias == True and (type(bias) == type(np.array([]))):\n",
    "            if len(bias.shape) == 1 and bias.shape[0] == self.out_channels:\n",
    "                self.bias_weights = bias\n",
    "            else:\n",
    "                raise TypeError(\"Invalid bias weights shape\")\n",
    "        if self.bias == True and (type(bias) != type(np.array([]))):\n",
    "            raise TypeError(\"Invalid bias weights\")\n",
    "        \n",
    "        if type(weights) != type(np.array([])):\n",
    "            raise TypeError(\"Invalid weights\")\n",
    "        if len(weights.shape) != 4:\n",
    "            raise ValueError(\"Invalid weights shape\")\n",
    "        if weights.shape[0] != self.in_channels:\n",
    "            raise ValueError(f\"Incorrect axis=0 weights dimension, given {weights.shape[0]}, expected {self.in_channels}\")\n",
    "        if weights.shape[1] != self.out_channels // self.groups:\n",
    "            raise ValueError(f\"Incorrect axis=1 weights dimension, given {weights.shape[1]}, expected {self.out_channels // self.groups}\")\n",
    "        if weights.shape[2] != self.kernel1:\n",
    "            raise ValueError(f\"Incorrect axis=2 weights dimension, given {weights.shape[2]}, expected {self.kernel1}\")\n",
    "        if weights.shape[3] != self.kernel2:\n",
    "            raise ValueError(f\"Incorrect axis=3 weights dimension, given {weights.shape[3]}, expected {self.kernel2}\")\n",
    "        self.weights = weights\n",
    "        \n",
    "    \n",
    "    def __get_conv(self, channels, h_in, w_in, offset=0, bias_offset=0):\n",
    "        size1 = (h_in - 1) * self.stride1 + self.dilation1 * (self.kernel1 - 1) + 1\n",
    "        size2 = (w_in - 1) * self.stride2 + self.dilation2 * (self.kernel2 - 1) + 1\n",
    "        conv = []\n",
    "        for i in range(len(channels)):\n",
    "            ch_list = []\n",
    "            ch = channels[i]\n",
    "            for b, k in enumerate(self.weights[i+offset]):\n",
    "                f_map = np.zeros((size1, size2))\n",
    "                x, y = 0, 0\n",
    "                for m in range(ch.shape[0]):\n",
    "                    for n in range(ch.shape[1]):\n",
    "                        x, y = n * self.stride2, m * self.stride1\n",
    "                        d = ch[m][n]\n",
    "                        t_conv = k * d\n",
    "                        y_m = y + self.kernel1 + (self.kernel1 - 1) * (self.dilation1 - 1)\n",
    "                        x_m = x + self.kernel2 + (self.kernel2 - 1) * (self.dilation2 - 1)\n",
    "                        #print(t_conv)\n",
    "                        #print(t_conv.shape)\n",
    "                        #print(x, x_m)\n",
    "                        #print(y, y_m)\n",
    "                        f_map[y:y_m:self.dilation1, x:x_m:self.dilation2] += t_conv\n",
    "            \n",
    "                for _ in range(self.output_padding1):\n",
    "                    f_map = np.vstack((f_map, np.zeros((1, f_map.shape[1]))))\n",
    "                for _ in range(self.output_padding2):\n",
    "                    f_map = np.hstack((f_map, np.zeros((f_map.shape[0], 1))))\n",
    "                for _ in range(self.padding1):\n",
    "                    f_map = f_map[1:-1]\n",
    "                for _ in range(self.padding2):\n",
    "                    f_map = f_map[:, 1:-1]\n",
    "                if self.bias:\n",
    "                    f_map += self.bias_weights[b + bias_offset] / len(channels)\n",
    "                ch_list.append(f_map)\n",
    "            conv.append(ch_list)\n",
    "        conv = np.asarray(conv)\n",
    "        conv = np.sum(conv, axis=0)\n",
    "        return conv\n",
    "    \n",
    "    def forward(self, tensor):\n",
    "        if len(tensor.shape) == 3:\n",
    "            tensor = np.expand_dims(tensor, axis=0)\n",
    "        if len(tensor.shape) != 4:\n",
    "            raise ValueError(f\"Invalid tensor dimensions = {len(tensor.shape)}, expected 3 or 4\")\n",
    "        N, c_in, h_in, w_in = tensor.shape\n",
    "                \n",
    "        c_out = self.out_channels\n",
    "        h_out = int((h_in - 1) * self.stride1 - 2 * self.padding1 + self.dilation1 * (self.kernel1 - 1) + self.output_padding1 + 1)\n",
    "        w_out = int((w_in - 1) * self.stride2 - 2 * self.padding2 + self.dilation2 * (self.kernel2 - 1) + self.output_padding2 + 1)\n",
    "        try:\n",
    "            out_tensor = np.zeros((N, c_out, h_out, w_out), dtype=self.dtype)\n",
    "        except:\n",
    "            raise TypeError(\"Invalid dtype\")\n",
    "        \n",
    "        for n in range(N):\n",
    "            cur_out_channel = 0\n",
    "            step_for_bias = self.out_channels // self.groups\n",
    "            step_for_channels = c_in // self.groups\n",
    "            ch_pos = 0\n",
    "            bias_pos = 0\n",
    "            for i in range(self.groups):\n",
    "                current_channels = tensor[n, ch_pos:ch_pos+step_for_channels]\n",
    "                conv = self.__get_conv(current_channels, h_in, w_in, offset=ch_pos, bias_offset=bias_pos)\n",
    "                ch_pos += step_for_channels\n",
    "                bias_pos += step_for_bias\n",
    "                for c in conv:\n",
    "                    out_tensor[n, cur_out_channel] = c\n",
    "                    cur_out_channel += 1\n",
    "        return out_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e28161d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "970ee20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32e334cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def test():\n",
    "    for i in (pbar := tqdm(range(10))):\n",
    "        t = rng.integers(low=0, high=255, size=(1, in_channels, 10, 10)) / 1.0\n",
    "        tt = torch.Tensor(t)\n",
    "        t_conv = torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size,\n",
    "                                 bias=bias, groups=groups, stride=stride,\n",
    "                                 padding=padding, output_padding=output_padding, dilation=dilation)\n",
    "\n",
    "        # берем случайные веса из слоя torch и записываем их в наш кастомный класс\n",
    "        weights = t_conv.weight.detach().numpy()\n",
    "        if bias:\n",
    "            bias_w = t_conv.bias.detach().numpy()\n",
    "        layer = ConvTranspose2D(in_channels, out_channels, kernel_size,\n",
    "                                 bias=bias, groups=groups, stride=stride,\n",
    "                                 padding=padding, output_padding=output_padding, dilation=dilation)\n",
    "        if bias:\n",
    "            layer.set_weights(weights, bias_w)\n",
    "        else:\n",
    "            layer.set_weights(weights)\n",
    "        torch_result = t_conv(tt).detach().numpy()\n",
    "        layer_result = layer.forward(t)\n",
    "        \n",
    "        assert np.allclose(torch_result, layer_result, atol=0.0001), \"Error\"\n",
    "    print('pass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f58db1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# первая группа\n",
    "kernel_size = (3, 3)\n",
    "padding = 1\n",
    "dilation = 1\n",
    "stride = 1\n",
    "in_channels = 8\n",
    "out_channels = 20\n",
    "bias = True\n",
    "groups = 2\n",
    "output_padding = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f487f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 16.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a570ab92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# вторая группа\n",
    "kernel_size = (4, 2)\n",
    "padding = 1\n",
    "dilation = 1\n",
    "stride = 1\n",
    "in_channels = 8\n",
    "out_channels = 20\n",
    "bias = True\n",
    "groups = 2\n",
    "output_padding = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5cf8865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 16.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c8be4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# третья группа\n",
    "kernel_size = (2, 4)\n",
    "padding = 0\n",
    "dilation = 1\n",
    "stride = 2\n",
    "in_channels = 4\n",
    "out_channels = 16\n",
    "bias = True\n",
    "groups = 4\n",
    "output_padding = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f45691b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 75.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6947badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# четвертая группа\n",
    "kernel_size = (2, 4)\n",
    "padding = 0\n",
    "dilation = 3\n",
    "stride = 2\n",
    "in_channels = 8\n",
    "out_channels = 20\n",
    "bias = True\n",
    "groups = 2\n",
    "output_padding = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d26af40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 17.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ee6e863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# пятая группа\n",
    "kernel_size = (5, 3)\n",
    "padding = 2\n",
    "dilation = 2\n",
    "stride = (3, 1)\n",
    "in_channels = 16\n",
    "out_channels = 8\n",
    "bias = True\n",
    "groups = 1\n",
    "output_padding = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42881133",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c4b0eb",
   "metadata": {},
   "source": [
    "### Реализация транспонированной свертки через обычную"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8009e443",
   "metadata": {},
   "source": [
    "Т.к. формат весов для обычной и транспонированной свертки слегка отличается, а именно, для Conv2D это (out_channels, input_channels/groups, kernel_size[0], kernel_size[1]), а для ConvTranspose2D это (in_channels, out_channels/groups, kernel_size[0], kernel_size[1]), то для задания одинаковых весов слегка изменим логику работы обычного класса Conv2D."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d44a70",
   "metadata": {},
   "source": [
    "Также следует отметить, что при реализации транспонированной свертки через обычную теряется возможность управления некоторыми параметрами, а именно padding, output_padding и dilation. Несмотря на то, что существуют некоторые редкие \"специфичные\" библиотечные реализации, позволяющие задавать эти параметры их реализация, очевидно, выходит за рамки рассматриваемой темы, поэтому единственными параметрами, которыми можно будет управлять это in_channels, out_channels, kernel_size, stride и groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1eee99ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# меняем класс под нормальную логику работы с groups\n",
    "import numpy as np\n",
    "class Conv2D():\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 stride=1, padding=0, output_padding=0, dilation=1, groups=1,\n",
    "                 bias=True, padding_mode='zeros', dtype=None):\n",
    "        \n",
    "        self.weights = None\n",
    "        self.bias_weights = None\n",
    "        \n",
    "        self.dtype = dtype\n",
    "        \n",
    "        padding_modes = ['zeros', 'replicate']\n",
    "        if padding_mode not in padding_modes:\n",
    "            raise ValueError(\"Invalid padding_mode\")\n",
    "        self.padding_mode = padding_mode\n",
    "        \n",
    "        if isinstance(in_channels, int) and in_channels > 0:\n",
    "            self.in_channels = in_channels\n",
    "        else:\n",
    "            raise ValueError(\"Invalid in_channels\")\n",
    "        \n",
    "        if isinstance(out_channels, int) and out_channels > 0:\n",
    "            self.out_channels = out_channels\n",
    "        else:\n",
    "            raise ValueError(\"Invalid out_channels\")\n",
    "        \n",
    "        if isinstance(groups, int) and groups > 0:\n",
    "            self.groups = groups\n",
    "        else:\n",
    "            raise ValueError(\"Invalid groups\")\n",
    "        \n",
    "        if isinstance(bias, int) or isinstance(bias, bool):\n",
    "            self.bias = bool(bias)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid bias\")\n",
    "        \n",
    "        if isinstance(kernel_size, tuple):\n",
    "            try:\n",
    "                self.kernel1, self.kernel2 = kernel_size\n",
    "                if not (isinstance(self.kernel1, int) and isinstance(self.kernel2, int)):\n",
    "                    raise ValueError(\"Invalid kernel_size types\")\n",
    "            except ValueError:\n",
    "                raise ValueError(\"Invalid tuple format for kernel_size\")\n",
    "        elif isinstance(kernel_size, int) and kernel_size > 0:\n",
    "            self.kernel1 = self.kernel2 = kernel_size\n",
    "        else:\n",
    "            raise ValueError(\"Invalid kernel_size\")\n",
    "        \n",
    "        if isinstance(stride, tuple):\n",
    "            try:\n",
    "                self.stride1, self.stride2 = stride\n",
    "                if not (isinstance(self.stride1, int) and isinstance(self.stride2, int)):\n",
    "                    raise ValueError(\"Invalid stride types\")\n",
    "            except ValueError:\n",
    "                raise ValueError(\"Invalid tuple format for stride\")\n",
    "        elif isinstance(stride, int) and stride > 0:\n",
    "            self.stride1 = self.stride2 = stride\n",
    "        else:\n",
    "            raise ValueError(\"Invalid stride\")\n",
    "        \n",
    "        if isinstance(padding, str):\n",
    "            if padding in [\"valid\", \"same\"]:\n",
    "                if padding == 'same' and self.stride1 != 1:\n",
    "                    raise ValueError(\"padding 'same' is not valid for stride > 1\")\n",
    "                self.padding1 = self.padding2 = padding\n",
    "            else:\n",
    "                raise ValueError(\"Invalid padding\")\n",
    "        elif isinstance(padding, tuple):\n",
    "            try:\n",
    "                self.padding1, self.padding2 = padding\n",
    "                if not (isinstance(self.padding1, int) and isinstance(self.padding2, int)):\n",
    "                    raise ValueError(\"Invalid padding types\")\n",
    "            except ValueError:\n",
    "                raise ValueError(\"Invalid tuple format for padding\")\n",
    "        elif isinstance(padding, int) and padding > -1:\n",
    "            self.padding1 = self.padding2 = padding\n",
    "        else:\n",
    "            raise ValueError(\"Invalid padding\")\n",
    "            \n",
    "        if isinstance(dilation, tuple):\n",
    "            try:\n",
    "                self.dilation1, self.dilation2 = dilation\n",
    "                if not (isinstance(self.dilation1, int) and isinstance(self.dilation2, int)):\n",
    "                    raise ValueError(\"Invalid dilation types\")\n",
    "            except ValueError:\n",
    "                raise ValueError(\"Invalid tuple format for dilation\")\n",
    "        elif isinstance(dilation, int) and dilation > 0:\n",
    "            self.dilation1 = self.dilation2 = dilation\n",
    "        else:\n",
    "            raise ValueError(\"Invalid dilation\")\n",
    "        if not((self.in_channels % self.groups == 0) and (self.out_channels % self.groups == 0)):\n",
    "            raise ValueError(\"in_channels and out_channels must both be divisible by groups\")\n",
    "            \n",
    "    def set_weights(self, weights, bias = None):\n",
    "        if self.bias == True and (type(bias) == type(np.array([]))):\n",
    "            if len(bias.shape) == 1 and bias.shape[0] == self.out_channels:\n",
    "                self.bias_weights = bias\n",
    "            else:\n",
    "                raise TypeError(\"Invalid bias weights shape\")\n",
    "        if self.bias == True and (type(bias) != type(np.array([]))):\n",
    "            raise TypeError(\"Invalid bias weights\")\n",
    "        \n",
    "        if type(weights) != type(np.array([])):\n",
    "            raise TypeError(\"Invalid weights\")\n",
    "        if len(weights.shape) != 4:\n",
    "            raise ValueError(\"Invalid weights shape\")\n",
    "        if weights.shape[0] != self.in_channels:\n",
    "            raise ValueError(f\"Incorrect axis=0 weights dimension, given {weights.shape[0]}, expected {self.in_channels}\")\n",
    "        if weights.shape[1] != self.out_channels // self.groups:\n",
    "            raise ValueError(f\"Incorrect axis=1 weights dimension, given {weights.shape[1]}, expected {self.out_channels // self.groups}\")\n",
    "        if weights.shape[2] != self.kernel1:\n",
    "            raise ValueError(f\"Incorrect axis=2 weights dimension, given {weights.shape[2]}, expected {self.kernel1}\")\n",
    "        if weights.shape[3] != self.kernel2:\n",
    "            raise ValueError(f\"Incorrect axis=3 weights dimension, given {weights.shape[3]}, expected {self.kernel2}\")\n",
    "        self.weights = weights\n",
    "        \n",
    "    \n",
    "    def __get_conv(self, channels, h_out, w_out, offset=0, bias_offset=0):\n",
    "        k1_m = self.kernel1 + (self.kernel1 - 1) * (self.dilation1 - 1)\n",
    "        k2_m = self.kernel2 + (self.kernel2 - 1) * (self.dilation2 - 1)\n",
    "        conv = []\n",
    "        \n",
    "        for i in range(len(channels)):\n",
    "            ch_list = []\n",
    "            ch = channels[i]\n",
    "            for h in range(self.padding1):\n",
    "                if (self.padding_mode == 'zeros'):\n",
    "                    ch = np.vstack((ch, np.zeros(ch.shape[1])))\n",
    "                    ch = np.vstack((np.zeros(ch.shape[1]), ch))\n",
    "                elif (self.padding_mode == 'replicate'):\n",
    "                    ch = np.vstack((ch, np.array(ch[-1])))\n",
    "                    ch = np.vstack((np.array(ch[0]), ch))\n",
    "\n",
    "            for w in range(self.padding2):\n",
    "                if (self.padding_mode == 'zeros'):\n",
    "                    ch = np.hstack((ch, np.zeros((ch.shape[0], 1))))\n",
    "                    ch = np.hstack((np.zeros((ch.shape[0], 1)), ch))\n",
    "                elif (self.padding_mode == 'replicate'):\n",
    "                    ch = np.hstack((ch, np.expand_dims(np.array(ch[:, -1]), axis=0).T))\n",
    "                    ch = np.hstack((np.expand_dims(np.array(ch[:, 0]), axis=0).T, ch))\n",
    "\n",
    "            if ch.shape[0] < k1_m or ch.shape[1] < k2_m:\n",
    "                raise RuntimeError(f\"Channel shape which is {ch.shape} smaller than calculated kernel {k1_m, k2_m}\")\n",
    "            \n",
    "            for b, k in enumerate(self.weights[i+offset]):\n",
    "                out = np.zeros((h_out, w_out), dtype=self.dtype)\n",
    "                m_ind, n_ind = 0, 0\n",
    "                x, y = 0, 0\n",
    "                m, n = out.shape\n",
    "                while m_ind < m:\n",
    "                    x = 0\n",
    "                    n_ind = 0\n",
    "                    while n_ind < n:\n",
    "                        out[m_ind, n_ind] += np.sum(ch[y:k1_m+y:self.dilation1, x:k2_m+x:self.dilation2] * k)\n",
    "                        n_ind += 1\n",
    "                        x += self.stride2\n",
    "                    y += self.stride1\n",
    "                    m_ind += 1\n",
    "                if self.bias:\n",
    "                    out += self.bias_weights[b+bias_offset] / len(channels)\n",
    "                \n",
    "                ch_list.append(out)\n",
    "            \n",
    "            conv.append(ch_list)\n",
    "        \n",
    "        conv = np.asarray(conv)\n",
    "        conv = np.sum(conv, axis=0)    \n",
    "        \n",
    "        return conv    \n",
    "    \n",
    "    \n",
    "    def forward(self, tensor):\n",
    "        if len(tensor.shape) == 3:\n",
    "            tensor = np.expand_dims(tensor, axis=0)\n",
    "        if len(tensor.shape) != 4:\n",
    "            raise ValueError(f\"Invalid tensor dimensions = {len(tensor.shape)}, expected 3 or 4\")\n",
    "        N, c_in, h_in, w_in = tensor.shape\n",
    "        k1_m = self.kernel1 + (self.kernel1 - 1) * (self.dilation1 - 1)\n",
    "        k2_m = self.kernel2 + (self.kernel2 - 1) * (self.dilation2 - 1)\n",
    "        if self.padding1 == 'valid':\n",
    "            self.padding1 = self.padding2 = 0\n",
    "        if self.padding1 == 'same':\n",
    "            self.padding1 = int((h_in * self.stride1 - self.stride1 - h_in + self.dilation1 * (self.kernel1 - 1) + 1) / 2)\n",
    "            self.padding2 = int((w_in * self.stride2 - self.stride2 - w_in + self.dilation2 * (self.kernel2 - 1) + 1) / 2)\n",
    "                \n",
    "        c_out = self.out_channels\n",
    "        h_out = int((h_in + 2 * self.padding1 - self.dilation1 * (self.kernel1 - 1) - 1) / self.stride1) + 1\n",
    "        w_out = int((w_in + 2 * self.padding2 - self.dilation2 * (self.kernel2 - 1) - 1) / self.stride2) + 1\n",
    "        try:\n",
    "            out_tensor = np.zeros((N, c_out, h_out, w_out), dtype=self.dtype)\n",
    "        except:\n",
    "            raise TypeError(\"Invalid dtype\")\n",
    "        \n",
    "        for n in range(N):\n",
    "            cur_out_channel = 0\n",
    "            step_for_bias = self.out_channels // self.groups\n",
    "            step_for_channels = c_in // self.groups\n",
    "            ch_pos = 0\n",
    "            bias_pos = 0\n",
    "            for i in range(self.groups):\n",
    "                current_channels = tensor[n, ch_pos:ch_pos+step_for_channels]\n",
    "                conv = self.__get_conv(current_channels, h_out, w_out, offset=ch_pos, bias_offset=bias_pos)\n",
    "                ch_pos += step_for_channels\n",
    "                bias_pos += step_for_bias\n",
    "                for c in conv:\n",
    "                    out_tensor[n, cur_out_channel] = c\n",
    "                    cur_out_channel += 1\n",
    "        return out_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fef6aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tensor(tensor, stride, kernel_size):\n",
    "    '''\n",
    "    Данная функция выполняет преобразование исходного тензора, для возможности применения обычной 2D свертки,\n",
    "    с целью получить результат транспонированной свертки\n",
    "    \n",
    "    tensor - np.array, axis_count = 4;\n",
    "    stride - tuple;\n",
    "    kernel_size - tuple;\n",
    "    \n",
    "    return out_tensor - np.array, axis_count = 4\n",
    "    '''\n",
    "    stride_h, stride_w = stride\n",
    "    kernel_h, kernel_w = kernel_size\n",
    "    N, c_in, h_in, w_in = tensor.shape\n",
    "    h_out = 2 * (kernel_h - 1) + h_in + (h_in - 1) * (stride_h - 1)\n",
    "    w_out = 2 * (kernel_w - 1) + w_in + (w_in - 1) * (stride_w - 1)\n",
    "    out_tensor = np.zeros((N, c_in, h_out, w_out))\n",
    "    for n in range(N):\n",
    "        for c in range(c_in):\n",
    "            m = tensor[n, c] # входная мапа\n",
    "            y, x = kernel_h - 1, kernel_w - 1 # левый верхний угол для заполнения\n",
    "            y_m, x_m = h_out - kernel_h + 1, w_out - kernel_w + 1 # правый нижний угол\n",
    "            out_tensor[n, c, y:y_m:stride_h, x:x_m:stride_w] = m\n",
    "    return out_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db18f07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def test():\n",
    "    for i in (pbar := tqdm(range(10))):\n",
    "        t = rng.integers(low=0, high=255, size=(5, in_channels, 10, 10)) / 1.0\n",
    "        tt = torch.Tensor(t)\n",
    "        t_conv = torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size,\n",
    "                                 bias=bias, groups=groups, stride=stride)\n",
    "\n",
    "        # берем случайные веса из слоя torch и записываем их в наш кастомный класс\n",
    "        weights = t_conv.weight.detach().numpy()\n",
    "        if bias:\n",
    "            bias_w = t_conv.bias.detach().numpy()\n",
    "        layer = Conv2D(in_channels, out_channels, kernel_size,\n",
    "                                 bias=bias, groups=groups)\n",
    "        if bias:\n",
    "            layer.set_weights(np.flip(weights, axis=(3, 2)), bias_w)\n",
    "        else:\n",
    "            layer.set_weights(np.flip(weights, axis=(3, 2)))\n",
    "        torch_result = t_conv(tt).detach().numpy()\n",
    "        layer_result = layer.forward(preprocess_tensor(t, stride, kernel_size))\n",
    "        \n",
    "        assert np.allclose(torch_result, layer_result, atol=0.001), \"Error\"\n",
    "    print('pass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b4b8776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# первая группа\n",
    "kernel_size = (3, 3)\n",
    "stride = (1, 1)\n",
    "in_channels = 16\n",
    "out_channels = 8\n",
    "bias = True\n",
    "groups = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bc8f750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3416d35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# вторая группа\n",
    "kernel_size = (2, 4)\n",
    "stride = (4, 2)\n",
    "in_channels = 4\n",
    "out_channels = 20\n",
    "bias = True\n",
    "groups = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "763a283e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9979085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# третья группа\n",
    "kernel_size = (3, 2)\n",
    "stride = (5, 3)\n",
    "in_channels = 20\n",
    "out_channels = 60\n",
    "bias = True\n",
    "groups = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9aaaac83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:57<00:00, 11.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c4c0b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# четвертая группа\n",
    "kernel_size = (7, 7)\n",
    "stride = (2, 2)\n",
    "in_channels = 3\n",
    "out_channels = 32\n",
    "bias = True\n",
    "groups = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6931a999",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:21<00:00,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
